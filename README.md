# CoffeeOverFlow-Error
CoffeeOverFlow-Error team project


### Introduction (Kirian and liam)

## The issue (t)
The café has seen unprecedented growth and has expanded to hundreds of outlets across the country. Due to the demand the company 
is receiving, they need to figure out how they can best target new and returning customers, and also understand which products 
are selling well.

The company currently has no way of identifying trends, meaning they are potentially losing out on major revenue streams. They are 
experiencing issues with collating and analysing the data they are producing at each branch, as their technical setup is limited.

• The software currently being used only generates reports for single branches.
• It is time consuming to collate data on all branches.
• Gathering meaningful data for the company on the whole is difficult, due to the limitations of the software.


## current setup
Every day, the following occurs for each branch:
• A CSV file containing data about every transaction they made for that day is generated.
• At 8pm, the data is uploaded to a piece of software installed in the back office computers.
• Daily, weekly or monthly reports for sales figures and other related business metrics are created.

## the solution
After a thorough analysis and discovery of what the client is looking for, a plan has been fleshed out. We will 
build a fully scalable ETL (Extract, Transform, Load) pipeline to handle large volumes of transaction data
for the business. This pipeline will collect all the transaction data generated by each individual café and place it
in a single location. By being able to easily query the company's data as a whole, the client will drastically increase their
ability to identify company-wide trends and insights.

## How to Push Branches fro VsCode to Github

![Alt text](<GIT CHEATSHEET (unfinished)1024_3.jpg>) ![Alt text](<GIT CHEATSHEET (unfinished)1024_4.jpg>) ![Alt text](<GIT CHEATSHEET (unfinished)1024_1.jpg>) ![Alt text](<GIT CHEATSHEET (unfinished)1024_2.jpg>)
## System requirements

# For Sprint 1:

- Operating system: Windows, macOS, or Linux.
- A 64-bit chip
- At least 4GB of RAM (8GB recommended)
- Hyper-v (on Windows)
- Virtualisation enabled on BIOS/UEFI (Windows and Linux systems)
- Docker
- Python 3
- A modern browser (Safari, Firefox, Chrome, Edge...)
- An integrated Development environment (Visual Studio Code, Xcode, Pycharm, or similar)

## How to run the app (kirian and liam)

# Sprint 1 and 2

	•	How to run app
    Double click on "app.py" file using a Python IDE. For Visual Studio Code, open an integrated terminal in the top level folder, then **py app.py** (Windows) or **python3 app.py** 

	•	How the app works

    *app.py**

# Sprint 3
# Setup Grafana data source
    Connect to Redshift and CloudWatch (instructions in same file as previous ticket)
    ### Connecting Grafana to Redshift

        - Install the "Amazon Redshift" plugin
        - Add a "Redshift" datasource
        - Leave the _assumed role_ blank (as it defaults to the role on EC2 instance)
        - Set default region to `eu-west-1`
        - Select the redshift cluster in "Cluster Identifier"
        - Add your team's database user and database name


## Screenshots (jewen and kevin)

to-do

### Changelog and Roadmap (Sprints) (jewen and kevin)

## To run the program
1. Install dependencies pip install -r requirements.txt
1. Open a terminal in the folder src
1. Run python3 app.py or py app.py
## 0.1.1 (look up on the slides) - Sprint 1

- Difficulties:

to-do 

## 0.1.1 (look up on the slides) - Sprint 1

to-do
